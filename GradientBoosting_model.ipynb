{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 11)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "df = pd.read_csv(\"./data/Latest_Data_Science_Salaries.csv\",sep=\";\")\n",
    "\n",
    "# check data frame shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplace chaque modalité dont le nombre d'occurences est inferieur à 10 par une nouvelle modalité \n",
    "\n",
    "imbalanceCol = [\"Company Location\", \"Job Title\"]\n",
    "\n",
    "for col in imbalanceCol:\n",
    "    counts = df[col].value_counts()\n",
    "    modalities = counts[counts < 10].index.tolist()\n",
    "    df[col] = df[col].replace(modalities, f\"rare_{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanceCol = [\"Salary Currency\"]\n",
    "\n",
    "for col in imbalanceCol:\n",
    "    counts = df[col].value_counts()\n",
    "    modalities = counts[counts < 45].index.tolist()\n",
    "    df[col] = df[col].replace(modalities, f\"rare_{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \"\"\" \n",
    "        Cette methode permet de faire le preprocessing d'un dataset\n",
    "    \"\"\"\n",
    "    # colsReturns = getColumns(df,df.columns)\n",
    "\n",
    "    # newData = df[colsReturns]\n",
    "\n",
    "    newData = pd.get_dummies(df)\n",
    "\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df_detect_out) :\n",
    "    '''\n",
    "        Fonction permettant de detecter les valeurs aberrantes\n",
    "        @params df_detect_out est de type dataframme\n",
    "    '''\n",
    "    q1 = np.quantile(df_detect_out, 0.25)\n",
    "    q3 = np.quantile(df_detect_out, 0.75)\n",
    "    eiq= q3 - q1\n",
    "    li = q1 - (eiq * 1.5)\n",
    "    ls = q3 + (eiq * 1.5)\n",
    "    i  = list(df_detect_out.index[(df_detect_out<=li) | (df_detect_out>=ls)])\n",
    "    val= list(df_detect_out[i])\n",
    "    return i, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "index, val = detect_outliers(df[\"Salary\"])\n",
    "df.drop(index, axis=0, inplace=True)\n",
    "\n",
    "plt.figure(figsize=((4, 2)))\n",
    "plt.boxplot(df[\"Salary\"], vert=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "index, val = detect_outliers(df[\"Salary\"])\n",
    "\n",
    "plt.figure(figsize=((4, 2)))\n",
    "plt.boxplot(df[\"Salary\"], vert=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "index, val = detect_outliers(df[\"Salary\"])\n",
    "df.drop(index, axis=0, inplace=True)\n",
    "plt.figure(figsize=((4, 2)))\n",
    "plt.boxplot(df[\"Salary\"], vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data\n",
    "X = df.drop([\"Salary in USD\",\"Salary\"], 1)\n",
    "y = df[[\"Salary in USD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Job Title_AI Scientist</th>\n",
       "      <th>Job Title_Analytics Engineer</th>\n",
       "      <th>Job Title_Applied Data Scientist</th>\n",
       "      <th>Job Title_Applied Machine Learning Scientist</th>\n",
       "      <th>Job Title_Applied Scientist</th>\n",
       "      <th>Job Title_BI Analyst</th>\n",
       "      <th>Job Title_BI Data Analyst</th>\n",
       "      <th>Job Title_BI Developer</th>\n",
       "      <th>Job Title_Big Data Engineer</th>\n",
       "      <th>...</th>\n",
       "      <th>Employee Residence_Turkey</th>\n",
       "      <th>Employee Residence_Ukraine</th>\n",
       "      <th>Employee Residence_United Arab Emirates</th>\n",
       "      <th>Employee Residence_United Kingdom</th>\n",
       "      <th>Employee Residence_United States</th>\n",
       "      <th>Employee Residence_Uzbekistan</th>\n",
       "      <th>Employee Residence_Viet Nam</th>\n",
       "      <th>Company Size_Large</th>\n",
       "      <th>Company Size_Medium</th>\n",
       "      <th>Company Size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3198 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Job Title_AI Scientist  Job Title_Analytics Engineer  \\\n",
       "0        3                       0                             0   \n",
       "1        3                       0                             0   \n",
       "2        3                       0                             0   \n",
       "3        3                       0                             0   \n",
       "4        3                       0                             0   \n",
       "...    ...                     ...                           ...   \n",
       "3293     1                       0                             0   \n",
       "3294     1                       0                             0   \n",
       "3296     1                       0                             0   \n",
       "3297     0                       0                             0   \n",
       "3298     0                       0                             0   \n",
       "\n",
       "      Job Title_Applied Data Scientist  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "...                                ...   \n",
       "3293                                 0   \n",
       "3294                                 0   \n",
       "3296                                 0   \n",
       "3297                                 0   \n",
       "3298                                 0   \n",
       "\n",
       "      Job Title_Applied Machine Learning Scientist  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "3293                                             0   \n",
       "3294                                             0   \n",
       "3296                                             0   \n",
       "3297                                             0   \n",
       "3298                                             0   \n",
       "\n",
       "      Job Title_Applied Scientist  Job Title_BI Analyst  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "2                               0                     0   \n",
       "3                               0                     0   \n",
       "4                               0                     0   \n",
       "...                           ...                   ...   \n",
       "3293                            0                     0   \n",
       "3294                            0                     0   \n",
       "3296                            0                     0   \n",
       "3297                            0                     0   \n",
       "3298                            0                     0   \n",
       "\n",
       "      Job Title_BI Data Analyst  Job Title_BI Developer  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                             0                       0   \n",
       "3                             0                       0   \n",
       "4                             0                       0   \n",
       "...                         ...                     ...   \n",
       "3293                          0                       0   \n",
       "3294                          0                       0   \n",
       "3296                          0                       0   \n",
       "3297                          0                       0   \n",
       "3298                          0                       0   \n",
       "\n",
       "      Job Title_Big Data Engineer  ...  Employee Residence_Turkey  \\\n",
       "0                               0  ...                          0   \n",
       "1                               0  ...                          0   \n",
       "2                               0  ...                          0   \n",
       "3                               0  ...                          0   \n",
       "4                               0  ...                          0   \n",
       "...                           ...  ...                        ...   \n",
       "3293                            0  ...                          0   \n",
       "3294                            0  ...                          0   \n",
       "3296                            0  ...                          0   \n",
       "3297                            0  ...                          0   \n",
       "3298                            0  ...                          0   \n",
       "\n",
       "      Employee Residence_Ukraine  Employee Residence_United Arab Emirates  \\\n",
       "0                              0                                        0   \n",
       "1                              0                                        0   \n",
       "2                              0                                        0   \n",
       "3                              0                                        0   \n",
       "4                              0                                        0   \n",
       "...                          ...                                      ...   \n",
       "3293                           0                                        0   \n",
       "3294                           0                                        0   \n",
       "3296                           0                                        0   \n",
       "3297                           0                                        0   \n",
       "3298                           0                                        0   \n",
       "\n",
       "      Employee Residence_United Kingdom  Employee Residence_United States  \\\n",
       "0                                     0                                 1   \n",
       "1                                     0                                 1   \n",
       "2                                     0                                 1   \n",
       "3                                     0                                 1   \n",
       "4                                     0                                 1   \n",
       "...                                 ...                               ...   \n",
       "3293                                  0                                 0   \n",
       "3294                                  0                                 1   \n",
       "3296                                  0                                 1   \n",
       "3297                                  0                                 1   \n",
       "3298                                  0                                 1   \n",
       "\n",
       "      Employee Residence_Uzbekistan  Employee Residence_Viet Nam  \\\n",
       "0                                 0                            0   \n",
       "1                                 0                            0   \n",
       "2                                 0                            0   \n",
       "3                                 0                            0   \n",
       "4                                 0                            0   \n",
       "...                             ...                          ...   \n",
       "3293                              0                            0   \n",
       "3294                              0                            0   \n",
       "3296                              0                            0   \n",
       "3297                              0                            0   \n",
       "3298                              0                            0   \n",
       "\n",
       "      Company Size_Large  Company Size_Medium  Company Size_Small  \n",
       "0                      0                    1                   0  \n",
       "1                      0                    1                   0  \n",
       "2                      0                    1                   0  \n",
       "3                      0                    1                   0  \n",
       "4                      0                    1                   0  \n",
       "...                  ...                  ...                 ...  \n",
       "3293                   1                    0                   0  \n",
       "3294                   1                    0                   0  \n",
       "3296                   1                    0                   0  \n",
       "3297                   0                    0                   1  \n",
       "3298                   1                    0                   0  \n",
       "\n",
       "[3198 rows x 153 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelEnc = LabelEncoder()\n",
    "X[\"Year\"] = labelEnc.fit_transform(X[\"Year\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "    'alpha': [0.9, 0.95, 0.99]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1.0,\n",
       " 'n_estimators': 200,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_impurity_decrease': 0.2,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.1,\n",
       " 'alpha': 0.95}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# perform random search\n",
    "clf_rs = RandomizedSearchCV(GradientBoostingRegressor(), hyperparameters, cv = 5, n_iter = 20)\n",
    "random_search = clf_rs.fit(X_train, y_train)\n",
    "\n",
    "# identify best parameters from random search\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31275845904819466"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arbre = GradientBoostingRegressor(\n",
    "                                     max_depth=random_search.best_params_[\"max_depth\"],\n",
    "                                     min_samples_leaf=random_search.best_params_[\"min_samples_leaf\"],\n",
    "                                     min_samples_split=random_search.best_params_[\"min_samples_split\"],\n",
    "                                     min_weight_fraction_leaf=random_search.best_params_[\"min_impurity_decrease\"],\n",
    "                                     n_estimators=random_search.best_params_[\"n_estimators\"],\n",
    "                                     alpha=random_search.best_params_[\"alpha\"],\n",
    "                                     learning_rate=random_search.best_params_[\"learning_rate\"],\n",
    "                                     subsample=random_search.best_params_[\"subsample\"],\n",
    "                                     min_impurity_decrease=random_search.best_params_[\"min_impurity_decrease\"]\n",
    "\n",
    "                                     )\n",
    "model_arbre.fit(X_train,y_train)\n",
    "model_arbre.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # perform grid search\n",
    "# clf_gs = GridSearchCV(GradientBoostingRegressor(), hyperparameters, cv = 3)\n",
    "# grid_search = clf_gs.fit(X_train, y_train)\n",
    "\n",
    "# # identify best parameters from grid search\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_arbre1 = GradientBoostingRegressor(\n",
    "#                                      max_depth=grid_search.best_params_[\"max_depth\"],\n",
    "#                                      min_samples_leaf=grid_search.best_params_[\"min_samples_leaf\"],\n",
    "#                                      min_samples_split=grid_search.best_params_[\"min_samples_split\"],\n",
    "#                                      min_weight_fraction_leaf=0.0,\n",
    "#                                     #  n_estimators=grid_search.best_params_[\"n_estimators\"],\n",
    "#                                     #  bootstrap=grid_search.best_params_[\"bootstrap\"],\n",
    "#                                     #  max_features=grid_search.best_params_[\"max_features\"]\n",
    "\n",
    "                                     \n",
    "#                                      )\n",
    "# model_arbre1.fit(X_train,y_train)\n",
    "# model_arbre1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('alpha', 0.95),\n",
       "             ('learning_rate', 0.1),\n",
       "             ('max_depth', 5),\n",
       "             ('min_impurity_decrease', 0.0),\n",
       "             ('min_samples_leaf', 2),\n",
       "             ('min_samples_split', 5),\n",
       "             ('min_weight_fraction_leaf', 0.0),\n",
       "             ('n_estimators', 100),\n",
       "             ('subsample', 1.0)])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "# perform bayesian optimization\n",
    "clf_bo = BayesSearchCV(GradientBoostingRegressor(), hyperparameters, cv =5,  n_iter = 20)\n",
    "bayes_search = clf_bo.fit(X_train, y_train)\n",
    "\n",
    "# identify best parameters from bayesian optimization\n",
    "bayes_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.446944467592736"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arbre2 =GradientBoostingRegressor(\n",
    "                                     max_depth=bayes_search.best_params_[\"max_depth\"],\n",
    "                                     min_samples_leaf=bayes_search.best_params_[\"min_samples_leaf\"],\n",
    "                                     min_samples_split=bayes_search.best_params_[\"min_samples_split\"],\n",
    "                                     min_weight_fraction_leaf=0.0,\n",
    "                                     n_estimators=bayes_search.best_params_[\"n_estimators\"],\n",
    "                                     alpha=bayes_search.best_params_[\"alpha\"],\n",
    "                                     learning_rate=bayes_search.best_params_[\"learning_rate\"],\n",
    "                                     subsample=bayes_search.best_params_[\"subsample\"],\n",
    "                                     min_impurity_decrease=bayes_search.best_params_[\"min_impurity_decrease\"]\n",
    "\n",
    "                                     \n",
    "                                     )\n",
    "model_arbre2.fit(X_train,y_train)\n",
    "model_arbre2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les reseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "  model = keras.Sequential([\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_model = build_and_compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 3ms/step - loss: 147581.4219\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 147388.0156\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 146491.6406\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 144226.2500\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 139978.2656\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 133209.1406\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 123455.3281\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 110435.3125\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 94642.8828\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 78346.2344\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 64177.1836\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 54346.3516\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 49207.2539\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 46862.0977\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 45831.8867\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 45244.0820\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 44795.9297\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 44431.1602\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 44076.9648\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 43760.3984\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 43474.2656\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 43209.8789\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 42977.8672\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 42731.7422\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 42518.0586\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 42310.7852\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 42132.2109\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41950.0078\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41788.7344\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41636.1367\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41496.7891\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41356.4922\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41241.0039\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41102.6289\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 40986.5977\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40885.9219\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40771.3281\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40678.8320\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40578.2812\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40502.7227\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40417.6914\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40327.0781\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40255.5781\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40195.9336\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 40122.4688\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40062.0703\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40009.6562\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 39933.6562\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39883.9297\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39827.4805\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 39770.4219\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39717.1562\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39681.7148\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39618.9609\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39572.9023\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39523.5703\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39495.4609\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39444.0703\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39402.0312\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39367.9922\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 39326.1719\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39299.3008\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39273.7500\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39249.8750\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39223.3320\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39176.2227\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39154.0703\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39123.5781\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39094.5508\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39070.0508\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39051.5898\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39064.3047\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39007.8516\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38984.5820\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38964.1367\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38941.5430\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38917.3242\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38901.9453\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38881.3438\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38861.8711\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38854.7227\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38835.0625\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38810.9922\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38803.0352\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38783.4570\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38762.4570\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 38751.5078\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38735.9219\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 38724.1641\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38713.8945\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38714.6797\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38687.6328\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38675.2852\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38681.3555\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38638.1367\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38628.2422\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38622.7891\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38608.0234\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38596.2578\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38597.3398\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38604.8984\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38556.8984\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38551.3906\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38537.2500\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38526.9375\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38517.8906\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38501.3984\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38488.9844\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 38484.6641\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38470.8789\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38465.7422\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38455.3438\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38449.4336\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38433.4336\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38420.3477\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38413.6797\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38403.4805\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38400.8711\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38387.7461\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38380.3086\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38375.0625\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38369.0391\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38364.3594\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38359.9570\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38342.2852\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38338.4844\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38323.6172\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38323.2852\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38318.4375\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38311.1016\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38319.1680\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38307.4141\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38288.0039\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38297.5078\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38277.4062\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38278.7188\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38271.8164\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38267.2148\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38261.8477\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38246.7422\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38243.6172\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38237.3281\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38233.9531\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38228.3984\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38232.2812\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 38225.6680\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38242.6055\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38208.4492\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38204.3828\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38200.5195\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38202.9062\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38188.2812\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38201.9609\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38184.7695\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38182.2500\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38181.5664\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38179.8828\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38168.4844\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38160.8242\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38157.5156\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38151.5234\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38160.8047\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38146.0430\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38140.3125\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38140.6250\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38150.2031\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38148.5195\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38129.9805\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38119.0820\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38123.5742\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38124.3438\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38120.0977\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38111.2031\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38118.2227\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38115.8711\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38102.7852\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38098.7969\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38098.4219\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38102.9727\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38078.0234\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38088.0508\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38081.5469\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38084.2227\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38070.7695\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38078.4609\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38083.2344\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38064.9180\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38062.2891\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38064.0820\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38062.3906\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38055.8516\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38052.2109\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38048.6016\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38040.3945\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38036.8555\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38038.1367\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38042.3516\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38040.8594\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38030.8672\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38023.3477\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38018.3789\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38030.3594\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38023.6289\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38027.8672\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38013.0547\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38013.6406\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38002.4805\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37998.5938\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37998.3828\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37998.1172\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37986.7695\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37983.8164\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37985.2344\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37985.3320\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37982.1406\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37977.8906\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37980.7578\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37982.6211\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37980.9180\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37975.1797\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37963.0898\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37961.5312\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37960.3945\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37959.7070\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37955.7969\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37959.7812\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37960.5938\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37954.7188\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37938.1328\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37938.9922\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37947.1016\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37934.8789\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37932.3789\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37929.9844\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37929.6484\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37930.2539\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37929.1484\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37923.1758\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37930.9258\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37922.2656\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37914.9805\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37915.3672\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37908.1055\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37906.6914\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37919.0742\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37896.1719\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37908.0469\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37900.7617\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37895.3633\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37887.5117\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37894.9570\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37887.5703\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37888.8477\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37891.7305\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37881.1055\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37883.6289\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37878.0703\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37884.4609\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37866.5508\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37875.2031\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37864.2422\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37860.4570\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37865.9844\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37869.7031\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37857.6602\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37877.2461\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37854.5664\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37848.9336\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37845.2773\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37846.8633\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37847.7617\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37852.0586\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37840.5234\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37831.6914\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37835.4805\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37831.2578\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37840.0547\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37828.3047\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37822.6914\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37820.0703\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37825.4961\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37819.8164\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37816.5352\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37816.4766\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37810.8789\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37804.6875\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37822.9180\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37820.3828\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37812.7148\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37809.5469\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37798.4688\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37795.6016\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37792.9805\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37791.1445\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37788.4453\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37781.9180\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37791.5898\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37789.5625\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37785.6094\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37772.7305\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37773.1992\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37782.1250\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37785.0625\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37772.0078\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37787.7930\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37782.0859\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37778.6133\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37754.4688\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37762.4297\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37752.6016\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37754.9961\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37762.8086\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37761.6992\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37754.7500\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37756.9062\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37752.1641\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37755.3359\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37737.1133\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37743.2031\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37749.7617\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37735.0273\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37745.6641\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37736.9258\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37724.1992\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37738.3008\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37730.1992\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37720.9531\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37741.6562\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37725.7070\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37721.1523\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37706.7852\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37722.1680\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37711.3008\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37717.1680\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37703.9648\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37706.3047\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37710.6523\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37704.2344\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37704.9492\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37701.1367\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37696.0781\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37694.3906\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37688.9102\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37686.9883\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37691.9727\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37692.9375\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37688.4375\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37682.2734\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37679.6289\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37682.1992\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37669.7422\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37680.1445\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37680.1055\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37668.2109\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37674.5977\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37667.5820\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37668.7812\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37661.3594\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37668.0547\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37656.6797\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37661.0430\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37665.0000\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37657.3438\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37665.4219\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37651.7266\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37649.5781\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37652.9023\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37658.0977\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37652.8320\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37640.6250\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37645.6719\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37636.7305\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37634.5625\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37639.4023\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37645.3867\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37636.7148\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37643.6484\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37639.2852\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37646.9531\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37632.1172\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37637.3242\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37624.1250\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37622.7969\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37620.3086\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37617.0898\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37630.4570\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37635.6250\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37617.2148\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37618.3008\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37614.7930\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37613.1250\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37610.7461\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37608.6680\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37613.8750\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37622.0664\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37607.3242\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37628.3164\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37611.2227\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37607.8633\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37610.2031\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37613.3359\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37602.0000\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37593.6875\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37595.2734\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37598.8164\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37603.5547\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37596.8984\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37603.2266\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37603.8633\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37585.1641\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37583.2344\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37584.7500\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37585.0781\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37577.1133\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37588.6484\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37583.6484\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37611.6719\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37576.2969\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37568.6172\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37574.3633\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37568.6953\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37567.9961\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37569.8125\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37576.8672\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37567.0508\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37558.8633\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37563.1445\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37565.0117\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37552.1289\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37563.1406\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37571.1797\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37551.9766\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37567.3828\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37554.4531\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37545.5781\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37544.4492\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37549.8828\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37540.1328\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37544.9102\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37540.9805\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37538.8477\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37539.5703\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37535.5859\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37536.3555\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37539.5156\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37534.5352\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37532.1953\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37526.5781\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37524.4102\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37528.7852\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37521.5664\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37547.1445\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37531.8945\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37536.8750\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37528.3867\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37514.3984\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37526.9883\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37513.7500\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37525.1602\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37528.3203\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37510.1016\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37512.2305\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37510.0312\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37509.9922\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37517.1836\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37509.1484\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37507.1328\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37511.3086\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37495.4570\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37509.3242\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37502.1133\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37509.5312\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37498.6328\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37497.4102\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37515.8047\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37496.0391\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37500.3203\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37493.8516\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37492.2891\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37497.5664\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37490.0938\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37492.2422\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37484.9297\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37491.9609\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37501.5664\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37501.1836\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37483.4648\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37485.4336\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37478.8086\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37482.1914\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37490.6328\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37491.5156\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37483.9180\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37492.4102\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37473.1914\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37485.7656\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37467.5273\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37478.8516\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37461.3398\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 37463.6602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2927882bc40>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_model.fit(X_train,y_train,epochs=500,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5086007742190143"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred = rn_model.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn_model.save('model_rn1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model1():\n",
    "    # Couche d'entrée\n",
    "    inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "    \n",
    "    # Ajoutez les couches cachées avec les activations ReLU\n",
    "    x = layers.Dense(64, activation='relu')(inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    # Couche de sortie\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    # Créez le modèle en spécifiant les entrées et les sorties\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compilez le modèle avec les paramètres appropriés\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn1 = build_and_compile_model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2558, 153)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 147400.5000\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 123662.3516\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 48268.2070\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 43984.3359\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 42266.8164\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 41265.1797\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 40531.6875\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 40049.2109\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 39662.6602\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 39445.8398\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 39201.0391\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 39009.8555\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38970.1680\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38809.8945\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38715.0508\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38586.5234\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38645.2266\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38462.1641\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38446.9414\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38311.7969\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38228.0469\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38208.1992\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38198.1641\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 38165.8281\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38138.4531\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38022.4062\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38075.7188\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37874.4648\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37862.5117\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37900.0117\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 38013.0430\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37863.4688\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37926.0625\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37942.3320\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37802.3047\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37732.7656\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37773.9766\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37772.1758\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37818.5820\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37654.2031\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37663.7578\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37713.7109\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37659.7383\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37628.1250\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37673.6836\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37621.3906\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37651.0547\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37623.9180\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37611.4883\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37536.7305\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37592.5117\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37570.6133\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37610.1680\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37478.3711\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37495.3398\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37491.3242\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37498.0078\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37404.2383\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37490.1719\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37450.6914\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37441.1211\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37430.9102\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37454.2695\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37349.6875\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37409.0781\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37371.2344\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37391.1484\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37329.4727\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37389.6562\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37336.5820\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37322.3711\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37369.2891\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37306.4414\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37338.9609\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37254.8125\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37373.9062\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37259.8789\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37219.9531\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37236.8438\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37231.1445\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37216.5195\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37313.7852\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37250.1875\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37260.7695\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37249.9922\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37328.0977\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37311.1836\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37211.6406\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37224.2188\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37178.4844\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 37201.8789\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37184.4922\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37137.5938\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37158.9727\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37189.7852\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37167.0312\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 37145.8594\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37139.9023\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37205.2930\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 37096.2930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29202a8eb00>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rn1.fit(X_train,y_train,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49537809968176527"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred1 = model_rn1.predict(X_test)\n",
    "r2_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 153)]             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                9856      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,401\n",
      "Trainable params: 22,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
