{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 11)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "df = pd.read_csv(\"./data/Latest_Data_Science_Salaries.csv\",sep=\";\")\n",
    "\n",
    "# check data frame shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Title', 'Employment Type', 'Experience Level', 'Expertise Level',\n",
       "       'Salary', 'Salary Currency', 'Company Location', 'Salary in USD',\n",
       "       'Employee Residence', 'Company Size', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplace chaque modalité dont le nombre d'occurences est inferieur à 10 par une nouvelle modalité \n",
    "\n",
    "imbalanceCol = [\"Company Location\", \"Job Title\"]\n",
    "\n",
    "for col in imbalanceCol:\n",
    "    counts = df[col].value_counts()\n",
    "    modalities = counts[counts < 10].index.tolist()\n",
    "    df[col] = df[col].replace(modalities, f\"rare_{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanceCol = [\"Salary Currency\"]\n",
    "\n",
    "for col in imbalanceCol:\n",
    "    counts = df[col].value_counts()\n",
    "    modalities = counts[counts < 45].index.tolist()\n",
    "    df[col] = df[col].replace(modalities, f\"rare_{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \"\"\" \n",
    "        Cette methode permet de faire le preprocessing d'un dataset\n",
    "    \"\"\"\n",
    "    # colsReturns = getColumns(df,df.columns)\n",
    "\n",
    "    # newData = df[colsReturns]\n",
    "\n",
    "    newData = pd.get_dummies(df)\n",
    "\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 155)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data\n",
    "X = df.drop([\"Salary in USD\",\"Salary\"], 1)\n",
    "y = df[[\"Salary in USD\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_estimators': [100, 200, 500],                # Nombre d'arbres dans la forêt\n",
    "    'max_depth': [10, 20, 50,100,500,1000],                # Profondeur maximale des arbres\n",
    "    'min_samples_split': [2, 5, 10],                # Nombre minimum d'échantillons requis pour scinder un nœud interne\n",
    "    'min_samples_leaf': [1, 2, 4,10]                  # Nombre minimum d'échantillons requis dans une feuille\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# perform random search\n",
    "clf_rs = RandomizedSearchCV(RandomForestRegressor(), hyperparameters, cv = 3, n_iter = 20)\n",
    "random_search = clf_rs.fit(X_train, y_train)\n",
    "\n",
    "# identify best parameters from random search\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4495586046253258"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arbre = RandomForestRegressor(\n",
    "                                     max_depth=random_search.best_params_[\"max_depth\"],\n",
    "                                     min_samples_leaf=random_search.best_params_[\"min_samples_leaf\"],\n",
    "                                     min_samples_split=random_search.best_params_[\"min_samples_split\"],\n",
    "                                     min_weight_fraction_leaf=0.0,\n",
    "                                    #  n_estimators=random_search.best_params_[\"n_estimators\"],\n",
    "                                    #  bootstrap=random_search.best_params_[\"bootstrap\"],\n",
    "                                    #  max_features=random_search.best_params_[\"max_features\"]\n",
    "\n",
    "                                     \n",
    "                                     )\n",
    "model_arbre.fit(X_train,y_train)\n",
    "model_arbre.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # perform grid search\n",
    "# clf_gs = GridSearchCV(RandomForestRegressor(), hyperparameters, cv = 3)\n",
    "# grid_search = clf_gs.fit(X_train, y_train)\n",
    "\n",
    "# # identify best parameters from grid search\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_arbre1 = RandomForestRegressor(\n",
    "#                                      max_depth=grid_search.best_params_[\"max_depth\"],\n",
    "#                                      min_samples_leaf=grid_search.best_params_[\"min_samples_leaf\"],\n",
    "#                                      min_samples_split=grid_search.best_params_[\"min_samples_split\"],\n",
    "#                                      min_weight_fraction_leaf=0.0,\n",
    "#                                     #  n_estimators=grid_search.best_params_[\"n_estimators\"],\n",
    "#                                     #  bootstrap=grid_search.best_params_[\"bootstrap\"],\n",
    "#                                     #  max_features=grid_search.best_params_[\"max_features\"]\n",
    "\n",
    "                                     \n",
    "#                                      )\n",
    "# model_arbre1.fit(X_train,y_train)\n",
    "# model_arbre1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('max_depth', 1000),\n",
       "             ('min_samples_leaf', 2),\n",
       "             ('min_samples_split', 10),\n",
       "             ('n_estimators', 500)])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "# perform bayesian optimization\n",
    "clf_bo = BayesSearchCV(RandomForestRegressor(), hyperparameters, cv =3,  n_iter = 20)\n",
    "bayes_search = clf_bo.fit(X_train, y_train)\n",
    "\n",
    "# identify best parameters from bayesian optimization\n",
    "bayes_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45478108676043194"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arbre2 = RandomForestRegressor(\n",
    "                                    max_depth=bayes_search.best_params_[\"max_depth\"],\n",
    "                                     min_samples_leaf=bayes_search.best_params_[\"min_samples_leaf\"],\n",
    "                                     min_samples_split=bayes_search.best_params_[\"min_samples_split\"],\n",
    "                                     min_weight_fraction_leaf=0.0,\n",
    "                                     n_estimators=bayes_search.best_params_[\"n_estimators\"],\n",
    "                                    #  bootstrap=grid_search.best_params_[\"bootstrap\"],\n",
    "                                    #  max_features=grid_search.best_params_[\"max_features\"]\n",
    "                                    )\n",
    "model_arbre2.fit(X_train,y_train)\n",
    "model_arbre2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
